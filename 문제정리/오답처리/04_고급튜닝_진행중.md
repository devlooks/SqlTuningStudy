소트 수행 과정
- 대상 집합 sga 버퍼캐시 읽음
- 1차 -> Sort Area 에서 정렬 완료(Optimal)
- 1차 이상 -> 양이 많을 때 -> Temp 테이블 스페이스 이용 -> 저장 집합 (Sort Runs)
- Sort Area 에서 종료 -> Optimal Sort
  - 디스크 1번 기록 -> One pass 소트
  - 디스크 2번 기록 -> Multi pass 소트

AutoTrace 소트오퍼레이션
- sorts(memory) : 1, sorts(disk) : 1 => 두번 발생, 서로 연관 X
- Group by (중복제거에 사용) 또는 hash 사용
  -> sorts(memory) : 0, sorts(disk) : 0

소트 과정 -> 디스크 I/O  발생 -> temp 테이블 스페이스 이용 -> direct path read : temp 대기 이벤트

sort(aggregate) -> 집계  
sort(order by) -> 정렬  
sort(group by) -> group by 시 결과집합이 적을때 -> temp 사용 X, 정렬을 보장하지 않는다  
--> 인덱스 구성 이용 생략 가능

hash(group by) -> sort 대신 hash 사용(=sort group by)  

sort union/union-all -> 중복제거 기능으로 인해, 생략 불가능

Union / Union all 사용시 배타적 집합
  - pk 조회 여부, 범위 중복 여부, 중복가능컬럼 조회 여부

Union All 과 Union 부분 처리 -> 중복 범위 제거 해야 가능 

소트 연상 생략 = 부분 처리
  - 소트연상 생략 인덱스 구성 (등치 컬럼 + order by 컬럼)

java Application 커밋 -> 네트워크 경유 DB Call 발생

nologging -> Insert 문에만 사용(Direct Path Insert 에만 사용)

Array Processing 
  - Insert에서도 사용 가능
  - Insert into select 문으로 insert 문보다 느림
  - DB Call을 줄임 -> Array 단위가 높아질수록 성능이 높아지나 -> 개선율의 한계가 있음
  - 효과 극대화 하기 위해서는 모든 과정을 Array 단위 처리
  - PL/SQL보다 Java에서 사용시 개선율이 높음

Parallel 힌트 
- Alter session enable parallel dml;
- 설정이 없을 경우 -> Direct Path Insert (parallel 힌트 사용) 사용 불가능

Parse Call(애플리케이션 커서 캐싱X 경우)
  - 바인드 변수 사용해도 매번 발생
  - 딕셔너리 조회 -> Recursive Call  발생

함수에 SQL 내장 -> Recursive Call 발생 X -> 결과 집합 건수 만큼 실행

Recursive Call 줄이는 방법
1. 스칼라 쿼리 사용
2. Deterministic 함수 선언
3. Result 캐시 사용
4. Native 컴파일 

DB 내장형 함수 일관성
- Deterministic, Fetch Call 단위 캐싱
- 스칼라 서브 쿼리 + 함수
  -> 일관성 보장 X
- 조인 + 스칼라 서브쿼리 -> 일관성 보장 O

IN 조건 : 필터 조건 사용 -> 반복 I/O 발생 가능성이 높음
소트 생략 : 등치 + ORDER BY 컬럼 순으로 구성

1000건 + 5000만건 조인 + 카디널리티가 100건일 경우
- 일반적으로 조인은 지향 -> nl_sj 를 사용 + unnest -> 건마다 전체 읽기 불가능 하도록
- 일반적으로 조인 지향 -> no_unnest
  - 조건 서브쿼리 블록만 최적화 및 메인 -> 서브쿼리 테이블 조인 순서 고정 단, 카디널리티가 적을때만 nl_sj와 성능 비슷

주문 -> 1억건, 주문상품 -> 2억건 -> 평균 주문 상품 2건 -> 세미조인 -> 비효율적  
1달 100만건 -> 1년 1200만건 -> 랜덤 액세스 비효율  
쿼리 + NL 조인 사용시 -> 소트부하 + 랜덤액세스 비효율 -> 해시 조인 권장  


#실기
```
/*+ leading(p) use_hash(o) full(o) index(P 주문상품_X1) */
/*+ leading(p) use_hash(o) full(o) index_ffs(P 주문상품_PK) */
```
해시조인 사용 이유
  - 100개 골고루(100만건에서 상품 데이터가 골고루 존재)
  - 상품 코드 조건 -> 200만건 (한달 주문 100만건)
  - 골고루로 인해 중복도가 적음 -> Build Input (200만건 결과집합)
  - 주문 -> full 로 일고 Probe Input 처리
  - 주문 상품은 -> index_ffs 이용 index이용시, 성능 떨어질 가능성 높음



